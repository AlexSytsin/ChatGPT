Reproduction of GPT according to the paper "Attention is all you need"  
Our GPT was trained on FineWeb-Edu( 10 BT).
It surpasses the results of OpenAI GPT-2 (124M) ( 3.12 val loss, 2.85 val loss finetuning on OpenWebText) getting down to 2.9 val loss on FineWeb-Edu.
Gets 0.307 score on HellaSwag against 0.294 of OpenAI GPT-2.
